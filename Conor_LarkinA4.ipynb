{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaX39xdUgHTz02PyLGB/+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LarkinConor/Resume/blob/main/Conor_LarkinA4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE9cqgAV0AjJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/sample_data/River-and-Rail-Cantina.csv\")"
      ],
      "metadata": {
        "id": "TyH10rWa0oNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['user_name'] = df['user_name'].astype(str)\n",
        "df['rating'] = df['rating'].astype(str)\n",
        "df['rating'] = df['rating'].str.replace(' star rating', '')\n",
        "df['review_text'] = df['review_text'].astype(str)"
      ],
      "metadata": {
        "id": "mCxwxQIE1T8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['user_name'] = df['user_name'].str.strip(\"['']\")\n",
        "df['rating'] = df['rating'].str.strip(\"['']\")\n",
        "df['review_text'] = df['review_text'].str.strip(\"['']\")"
      ],
      "metadata": {
        "id": "BjcRcmaZ4W40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating'] = df['rating'].str.split(\"'\", expand=True).get(0) #Some people reviewed the restaurant twice and I couldn't figure out how to split the reviews so I just deleted the second review\n",
        "df['user_name'] = df['user_name'].str.split(\"'\", expand=True).get(0) #Some people had the amount of photos posted so I cleaned it up\n",
        "df['review_text'] = df['review_text'].str.split(\", '\", expand=True).get(0) #same as the ratings problem"
      ],
      "metadata": {
        "id": "kktoSKHj8Nfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating'] = df['rating'].astype(int)"
      ],
      "metadata": {
        "id": "83EMI7ay4oMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"Unnamed: 0\", axis=1, inplace=True) #I do not know where unnamed:  0 came from so I dropped it"
      ],
      "metadata": {
        "id": "0BK8WMF12sDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztny3-n0dqNR",
        "outputId": "63e80701-e1b3-4efe-927b-e2f1ccf817cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 766 entries, 0 to 765\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   review_date  766 non-null    object\n",
            " 1   user_name    766 non-null    object\n",
            " 2   rating       766 non-null    int64 \n",
            " 3   review_text  766 non-null    object\n",
            " 4   sentiment    766 non-null    object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 30.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recode_rating(rating):\n",
        "    if rating <= 3:\n",
        "        return 'Negative'\n",
        "    elif rating <= 5:\n",
        "        return 'Positive'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "df['sentiment'] = df['rating'].apply(recode_rating)"
      ],
      "metadata": {
        "id": "6iunAJiyAonZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqM360RcJ_SS",
        "outputId": "932cdfa4-3b3b-4c49-d608-c6679a3c6174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "baXZVM8zMCCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_review(review_text):\n",
        "    # Remove punctuation\n",
        "    review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n",
        "    \n",
        "    # Convert all words to lower case\n",
        "    review_text = review_text.lower()\n",
        "    \n",
        "    # Tokenize the review into words\n",
        "    words = word_tokenize(review_text)\n",
        "    \n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    \n",
        "    # Join the remaining words back into a single string\n",
        "    processed_review = ' '.join(words)\n",
        "    \n",
        "    return processed_review\n",
        "\n",
        "df['review_text'] = df['review_text'].apply(preprocess_review)"
      ],
      "metadata": {
        "id": "qHINq0z9MDoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "IJV8dCXCOmAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_reviews = []\n",
        "for review in df['review_text']:\n",
        "    tokens = tokenizer.tokenize(review.lower())\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    normalized_reviews.append(filtered_tokens)"
      ],
      "metadata": {
        "id": "UmFwreuUNzF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "for review in normalized_reviews:\n",
        "    vocabulary.update(review)"
      ],
      "metadata": {
        "id": "zW_8YcapOF3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_sets = []\n",
        "for i in range(len(normalized_reviews)):\n",
        "    features = {}\n",
        "    for word in vocabulary:\n",
        "        features[word] = normalized_reviews[i].count(word)\n",
        "    label = df['rating'][i]\n",
        "    feature_sets.append((features, label))"
      ],
      "metadata": {
        "id": "vQ0A3LGgOGwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(feature_sets)"
      ],
      "metadata": {
        "id": "PzY9uC4EOl9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff = int(0.7 * len(feature_sets))\n",
        "train_set = feature_sets[:cutoff]\n",
        "test_set = feature_sets[cutoff:]"
      ],
      "metadata": {
        "id": "W8dSYwcwOssV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
        "print(\"Classifier accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL7A2TbtPLDy",
        "outputId": "a3bfcb7b-47ad-4cef-ca1f-3e9fe3e385fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier accuracy: 0.4782608695652174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LJ8gKq4Pi4d",
        "outputId": "a6d795e1-b1fb-4041-dea8-c8e3d362a6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                   great = 2                   5 : 1      =     13.6 : 1.0\n",
            "               excellent = 1                   5 : 1      =     12.3 : 1.0\n",
            "              definitely = 1                   5 : 2      =     10.8 : 1.0\n",
            "                   could = 1                   1 : 5      =     10.4 : 1.0\n",
            "               delicious = 1                   5 : 1      =     10.2 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I struggled a lot with this a couldn't random the words of the reviews no matter what I tried so I went to Chatgpt and went from there. I don't exactly know where it went wrong but I think I did get the top five words but it says = 1 when I thought it should be = True\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DXUk9ODPxpB"
      }
    }
  ]
}